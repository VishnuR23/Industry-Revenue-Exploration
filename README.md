# Industry Revenue Exploration  

## 📌 Overview  
This project focuses on analyzing the **revenue of large corporations** by investigating multiple organizational factors. The workflow involved **web scraping**, **dataset creation**, **exploratory analysis**, and **machine learning modeling** to uncover which features most strongly influence a company’s revenue.  

---

## 🛠️ Project Workflow  

### 1. Data Collection  
- Utilized **web scraping** to gather data on large corporations.  
- Collected various attributes such as industry, size, region, and other organizational factors.  
- Exported the compiled dataset into a **CSV file** for further analysis.  

### 2. Data Exploration & Analysis  
- Conducted **exploratory data analysis (EDA)** to understand feature distributions and relationships.  
- Applied **visualization techniques** (scatter plots, bar charts, heatmaps) to identify trends and patterns in revenue across industries and company types.  

### 3. Feature Analysis  
- Measured relationships between features and revenue using **correlation matrices**.  
- Identified the factors with the highest influence on corporate revenue.  

### 4. Machine Learning Modeling  
- Built and evaluated models to test predictive relationships.  
- Trained/tested models (e.g., **Random Forests, regression models**) on the dataset.  
- Assessed performance metrics to validate predictive power.  

---

## 📊 Key Insights  
- Certain industry and organizational factors show strong correlation with **corporate revenue**.  
- Feature importance analysis from machine learning models highlights the **most prevalent drivers of revenue**.  
- The project demonstrates the effectiveness of combining **web scraping, data analysis, and ML techniques** for real-world financial insights.  

---

## 🚀 Technologies Used  
- **Python**  
- **BeautifulSoup**, **Requests** (web scraping)  
- **Pandas**, **NumPy** (data handling and preprocessing)  
- **Matplotlib**, **Seaborn** (data visualization)  
- **Scikit-learn** (modeling and feature importance analysis)  

---

## 📂 Project Structure  
├── data/ # Collected and cleaned datasets
├── notebooks/ # Jupyter notebooks with scraping, analysis, and modeling
├── src/ # Python scripts for scraping and ML pipelines
├── visualizations/ # Plots and charts generated during analysis
└── README.md # Project documentation
